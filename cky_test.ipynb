{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aae8e676-fd8c-4509-a945-f45510d544ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b0670a2c-4787-4fd4-9a6d-36369a523e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 0\n",
      "t = 1\n",
      "t = 2\n",
      "t = 3\n",
      "t = 4\n",
      "t = 5\n",
      "t = 6\n",
      "t = 7\n",
      "t = 8\n",
      "t = 9\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable\n",
    "def CKY_Algorithm(sequence, get_terminate_parses: Callable, beam_search_strategy: Callable = None, enable_slide_windows = False, window_size = -1):\n",
    "    if (enable_slide_windows and window_size <= 0) or sequence == None or len(sequence) == 0:\n",
    "        return None\n",
    "        \n",
    "    T = len(sequence)\n",
    "    records = []\n",
    "    windows_beginning_offset = 0\n",
    "    for t in range(T):\n",
    "        print(\"t = \" + str(t))\n",
    "        w = get_terminate_parses(sequence[t])\n",
    "        \n",
    "        current_record = [[]] if len(records) == 0 else [[]] * (len(records[-1]) + 1)\n",
    "        current_record[-1] = w\n",
    "\n",
    "        # When the windows size is large, we may utilize array to store records, rather than list. The array allow us adopting \n",
    "        # sliding windows more effectively when the window size is large. However, we currently utilize list to store records.\n",
    "        # To do sliding window, we need first pop the first record (oldest record inside the window), and for each of rest records,\n",
    "        # we need pop its first element, as the first element of each record relate to the \"word\" we'd like to forget.\n",
    "        if enable_slide_windows:\n",
    "            if len(records) == window_size:\n",
    "                records.pop(0)\n",
    "                for i in range(0, len(records)):\n",
    "                    records[i].pop(0)\n",
    "                windows_beginning_offset += 1\n",
    "                \n",
    "        records.append(current_record)\n",
    "\n",
    "        for inner_record_index in range(0, len(current_record) - 1):\n",
    "            current_record_length = len(current_record) \n",
    "            current_record[current_record_length - inner_record_index - 2] = []\n",
    "            cell_data = []\n",
    "            for split_index in range(current_record_length - inner_record_index - 2, t - windows_beginning_offset):\n",
    "                # coordination = (index, t)\n",
    "                cell1_coordination = (current_record_length - inner_record_index - 2, split_index)\n",
    "                cell2_coordination = (split_index + 1, t - windows_beginning_offset)\n",
    "                cell_data += merge_parses_in_two_cells(records[cell1_coordination[1]][cell1_coordination[0]],\\\n",
    "                                                       records[cell2_coordination[1]][cell2_coordination[0]],\\\n",
    "                                                       cell1_coordination, cell2_coordination)\n",
    "            current_record[current_record_length - inner_record_index - 2] = beam_search_strategy(cell_data) if beam_search_strategy is not None else cell_data\n",
    "    return records\n",
    "\n",
    "\n",
    "def get_terminate_parses(w):\n",
    "    return [\"(\" + str(w) + \", \" + str(w) + \")\"]\n",
    "\n",
    "def merge_parses_in_two_cells(cell1, cell2, cell1_id = None, cell2_id = None):\n",
    "    return [[cell1_id, cell2_id]]\n",
    "\n",
    "def select_tops(cell1, beam_size = 5):\n",
    "    return cell1[:beam_size]\n",
    "\n",
    "records = CKY_Algorithm(range(0, 10), get_terminate_parses, select_tops, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f1bb44bf-3fad-4929-9dba-238a0ba16137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0), (1, 9)],\n",
       " [(0, 1), (2, 9)],\n",
       " [(0, 2), (3, 9)],\n",
       " [(0, 3), (4, 9)],\n",
       " [(0, 4), (5, 9)]]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[-1][0] # (t, span_start_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41afbcea-ad92-4bcc-b9a9-05aa6c360544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313c2622-f4d2-4562-98bf-64d97954ed54",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "18d1b00a-5887-407b-8814-f81b9e739474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b7afcd-a41e-4f41-88ac-13d967e6bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_CYK_Model(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.device = 'cpu'\n",
    "        self.NT = args['NT']\n",
    "        self.T = args['T']\n",
    "        self.V = args['cnt_words']\n",
    "        self.s_dim = args['s_dim']\n",
    "        self.r = args['r_dim']\n",
    "        self.word_emb_size = args['word_emb_size']\n",
    "        self.enable_slide_windows = False if 'enable_slide_windows' not in args else args['enable_slide_windows']\n",
    "        self.window_size = False if 'window_size' not in args else args['window_size']\n",
    "        self.word_embedding = args['word_embedding']\n",
    "        self.grammar_unaries = args['grammar_unaries']\n",
    "        self.grammar_preterminates = args['grammar_preterminates']\n",
    "        self.grammar_double_nonterminates = args['grammar_double_nonterminates']\n",
    "        self.grammar_starts = args['grammar_starts']\n",
    "\n",
    "        self.merge_model = None # A -> BC\n",
    "        self.terminate_feature_generation_model = None # D -> E\n",
    "        self.preterminate_feature_generation_model = None # E -> w\n",
    "        \n",
    "        # check parameters\n",
    "        if (self.enable_slide_windows and self.window_size <= 0) or word == None\n",
    "            return None\n",
    "        reset_global_context()\n",
    "        \n",
    "    def reset_global_context(self):\n",
    "        self.records = []\n",
    "        self.windows_beginning_offset = 0\n",
    "\n",
    "    # each cell with form (possibility, feature_in_tensor, root_symbol_index)\n",
    "    def forward(self, word): # input a word at time t.\n",
    "        # generate the analysis of span [t, t]\n",
    "        w = self.get_terminate_parses(word)\n",
    "\n",
    "        # create cells for current time t.\n",
    "        current_record = [[]] if len(records) == 0 else [[]] * (len(records[-1]) + 1)\n",
    "\n",
    "        # fill the analysis of span [t, t] to the last cell of current time t.\n",
    "        current_record[-1] = w\n",
    "\n",
    "        # Sliding window control the maximum size of a record at time t.\n",
    "        # When the windows size is large, we may utilize array to store records, rather than list. The array allow us adopting \n",
    "        # sliding windows more effectively when the window size is large. However, we currently utilize list to store records.\n",
    "        # To do sliding window, we need first pop the first record (oldest record inside the window), and for each of rest records,\n",
    "        # we need pop its first element, as the first element of each record relate to the \"word\" we'd like to forget.\n",
    "        if enable_slide_windows:\n",
    "            while len(self.records) >= self.window_size:\n",
    "                self.records.pop(0)\n",
    "                for i in range(0, len(self.records)):\n",
    "                    self.records[i].pop(0)\n",
    "                windows_beginning_offset += 1\n",
    "\n",
    "        # Add record at current time to the global record set.\n",
    "        records.append(current_record)\n",
    "    \n",
    "        for inner_record_index in range(0, len(current_record) - 1):\n",
    "            current_record_length = len(current_record) \n",
    "            current_record[current_record_length - inner_record_index - 2] = []\n",
    "            cell_data = []\n",
    "            for split_index in range(current_record_length - inner_record_index - 2, t - windows_beginning_offset):\n",
    "                # coordination = (index, t)\n",
    "                cell1_coordination = (current_record_length - inner_record_index - 2, split_index)\n",
    "                cell2_coordination = (split_index + 1, t - windows_beginning_offset)\n",
    "                cell_data += self.merge_parses_in_two_cells(records[cell1_coordination[1]][cell1_coordination[0]],\\\n",
    "                                                           records[cell2_coordination[1]][cell2_coordination[0]],\\\n",
    "                                                           cell1_coordination, cell2_coordination)\n",
    "                current_record[current_record_length - inner_record_index - 2] = beam_search_strategy(cell_data) if beam_search_strategy is not None else cell_data\n",
    "        return heapq.nlargest(1, records[-1][0])[0][1]\n",
    "        \n",
    "        def get_unary_grammar_id(self, w):\n",
    "            return self.word_unary_grammar_id_mapping[w]\n",
    "\n",
    "        def get_grammar_for_generation(self, parse_i, parse_j):\n",
    "            return self.double_nonterminates_grammar_id_mapping[\"%s#%s\" % (str(parse_i[0]), str(parse_j[0]))]\n",
    "        \n",
    "        def get_terminate_parses(self, w):\n",
    "            unary_grammar_id = self.get_unary_grammar_id(w)\n",
    "            preterminate_grammar_id = self.preterminate_grammar_id(unary_grammar_id)\n",
    "            feature1 = self.terminate_feature_generation_model(self.word_embedding[w], self.grammar_unaries[unary_grammar_id])\n",
    "            feature2 = self.preterminate_feature_generation_model(feature1, self.grammar_preterminates[preterminate_grammar_id])\n",
    "            return [[1.0, feature1, unary_grammar_id], [1.0, feature2, preterminate_grammar_id]]\n",
    "        \n",
    "        def merge_parses_in_two_cells(self, cell1, cell2, cell1_id = None, cell2_id = None):\n",
    "            result = []\n",
    "            for parse_i in range(cell1):\n",
    "                for parse_j in range(cell2):\n",
    "                    p_1 = parse_i[0]\n",
    "                    p_2 = parse_j[1]\n",
    "                    g = self.get_grammar(parse_i, parse_j) # [begin_id, left_symbol_id, right_symbol_id, possibility]\n",
    "                    p = p_1 * p_2 * g[-1]\n",
    "                    feature = self.merge_model(parse_i[1], parse_j[2], g)\n",
    "                    result.append([p, feature, g[0]])\n",
    "            return result\n",
    "        \n",
    "        def select_tops(self, cell, beam_size = 5):\n",
    "            return heapq.nlargest(beam_size, cell)\n",
    "        \n",
    "records = CKY_Algorithm(range(0, 10), get_terminate_parses, select_tops, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d30b2c0-5560-444a-94db-6e83021925a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "aefcc85f-7746-43ac-839a-20c78b99a572",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'max'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[139], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.999\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m23124\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m9.45\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2124\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m33\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'max'"
     ]
    }
   ],
   "source": [
    "[(0.999, [23124]), (9.45, [2124,33])].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "155102a3-04f1-452f-a21b-2b7008d8c8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, [1, 2, 3]]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heapq.nlargest(1, [[1, [1,2,3]]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218e3624-6aa7-4ac1-88a0-7845029edfd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
