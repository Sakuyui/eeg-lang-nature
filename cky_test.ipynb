{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aae8e676-fd8c-4509-a945-f45510d544ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b0670a2c-4787-4fd4-9a6d-36369a523e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 0\n",
      "t = 1\n",
      "t = 2\n",
      "t = 3\n",
      "t = 4\n",
      "t = 5\n",
      "t = 6\n",
      "t = 7\n",
      "t = 8\n",
      "t = 9\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable\n",
    "def CKY_Algorithm(sequence, get_terminate_parses: Callable, beam_search_strategy: Callable = None, enable_slide_windows = False, window_size = -1):\n",
    "    if (enable_slide_windows and window_size <= 0) or sequence == None or len(sequence) == 0:\n",
    "        return None\n",
    "        \n",
    "    T = len(sequence)\n",
    "    records = []\n",
    "    windows_beginning_offset = 0\n",
    "    for t in range(T):\n",
    "        print(\"t = \" + str(t))\n",
    "        w = get_terminate_parses(sequence[t])\n",
    "        \n",
    "        current_record = [[]] if len(records) == 0 else [[]] * (len(records[-1]) + 1)\n",
    "        current_record[-1] = w\n",
    "\n",
    "        # When the windows size is large, we may utilize array to store records, rather than list. The array allow us adopting \n",
    "        # sliding windows more effectively when the window size is large. However, we currently utilize list to store records.\n",
    "        # To do sliding window, we need first pop the first record (oldest record inside the window), and for each of rest records,\n",
    "        # we need pop its first element, as the first element of each record relate to the \"word\" we'd like to forget.\n",
    "        if enable_slide_windows:\n",
    "            if len(records) == window_size:\n",
    "                records.pop(0)\n",
    "                for i in range(0, len(records)):\n",
    "                    records[i].pop(0)\n",
    "                windows_beginning_offset += 1\n",
    "                \n",
    "        records.append(current_record)\n",
    "\n",
    "        for inner_record_index in range(0, len(current_record) - 1):\n",
    "            current_record_length = len(current_record) \n",
    "            current_record[current_record_length - inner_record_index - 2] = []\n",
    "            cell_data = []\n",
    "            for split_index in range(current_record_length - inner_record_index - 2, t - windows_beginning_offset):\n",
    "                # coordination = (index, t)\n",
    "                cell1_coordination = (current_record_length - inner_record_index - 2, split_index)\n",
    "                cell2_coordination = (split_index + 1, t - windows_beginning_offset)\n",
    "                cell_data += merge_parses_in_two_cells(records[cell1_coordination[1]][cell1_coordination[0]],\\\n",
    "                                                       records[cell2_coordination[1]][cell2_coordination[0]],\\\n",
    "                                                       cell1_coordination, cell2_coordination)\n",
    "            current_record[current_record_length - inner_record_index - 2] = beam_search_strategy(cell_data) if beam_search_strategy is not None else cell_data\n",
    "    return records\n",
    "\n",
    "\n",
    "def get_terminate_parses(w):\n",
    "    return [\"(\" + str(w) + \", \" + str(w) + \")\"]\n",
    "\n",
    "def merge_parses_in_two_cells(cell1, cell2, cell1_id = None, cell2_id = None):\n",
    "    return [[cell1_id, cell2_id]]\n",
    "\n",
    "def select_tops(cell1, beam_size = 5):\n",
    "    return cell1[:beam_size]\n",
    "\n",
    "records = CKY_Algorithm(range(0, 10), get_terminate_parses, select_tops, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f1bb44bf-3fad-4929-9dba-238a0ba16137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0), (1, 9)],\n",
       " [(0, 1), (2, 9)],\n",
       " [(0, 2), (3, 9)],\n",
       " [(0, 3), (4, 9)],\n",
       " [(0, 4), (5, 9)]]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[-1][0] # (t, span_start_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "41afbcea-ad92-4bcc-b9a9-05aa6c360544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['(0, 0)']],\n",
       " [[[(0, 0), (1, 1)]], ['(1, 1)']],\n",
       " [[[(0, 0), (1, 2)], [(0, 1), (2, 2)]], [[(1, 1), (2, 2)]], ['(2, 2)']],\n",
       " [[[(0, 0), (1, 3)], [(0, 1), (2, 3)], [(0, 2), (3, 3)]],\n",
       "  [[(1, 1), (2, 3)], [(1, 2), (3, 3)]],\n",
       "  [[(2, 2), (3, 3)]],\n",
       "  ['(3, 3)']],\n",
       " [[[(0, 0), (1, 4)], [(0, 1), (2, 4)], [(0, 2), (3, 4)], [(0, 3), (4, 4)]],\n",
       "  [[(1, 1), (2, 4)], [(1, 2), (3, 4)], [(1, 3), (4, 4)]],\n",
       "  [[(2, 2), (3, 4)], [(2, 3), (4, 4)]],\n",
       "  [[(3, 3), (4, 4)]],\n",
       "  ['(4, 4)']],\n",
       " [[[(0, 0), (1, 5)],\n",
       "   [(0, 1), (2, 5)],\n",
       "   [(0, 2), (3, 5)],\n",
       "   [(0, 3), (4, 5)],\n",
       "   [(0, 4), (5, 5)]],\n",
       "  [[(1, 1), (2, 5)], [(1, 2), (3, 5)], [(1, 3), (4, 5)], [(1, 4), (5, 5)]],\n",
       "  [[(2, 2), (3, 5)], [(2, 3), (4, 5)], [(2, 4), (5, 5)]],\n",
       "  [[(3, 3), (4, 5)], [(3, 4), (5, 5)]],\n",
       "  [[(4, 4), (5, 5)]],\n",
       "  ['(5, 5)']],\n",
       " [[[(0, 0), (1, 6)],\n",
       "   [(0, 1), (2, 6)],\n",
       "   [(0, 2), (3, 6)],\n",
       "   [(0, 3), (4, 6)],\n",
       "   [(0, 4), (5, 6)]],\n",
       "  [[(1, 1), (2, 6)],\n",
       "   [(1, 2), (3, 6)],\n",
       "   [(1, 3), (4, 6)],\n",
       "   [(1, 4), (5, 6)],\n",
       "   [(1, 5), (6, 6)]],\n",
       "  [[(2, 2), (3, 6)], [(2, 3), (4, 6)], [(2, 4), (5, 6)], [(2, 5), (6, 6)]],\n",
       "  [[(3, 3), (4, 6)], [(3, 4), (5, 6)], [(3, 5), (6, 6)]],\n",
       "  [[(4, 4), (5, 6)], [(4, 5), (6, 6)]],\n",
       "  [[(5, 5), (6, 6)]],\n",
       "  ['(6, 6)']],\n",
       " [[[(0, 0), (1, 7)],\n",
       "   [(0, 1), (2, 7)],\n",
       "   [(0, 2), (3, 7)],\n",
       "   [(0, 3), (4, 7)],\n",
       "   [(0, 4), (5, 7)]],\n",
       "  [[(1, 1), (2, 7)],\n",
       "   [(1, 2), (3, 7)],\n",
       "   [(1, 3), (4, 7)],\n",
       "   [(1, 4), (5, 7)],\n",
       "   [(1, 5), (6, 7)]],\n",
       "  [[(2, 2), (3, 7)],\n",
       "   [(2, 3), (4, 7)],\n",
       "   [(2, 4), (5, 7)],\n",
       "   [(2, 5), (6, 7)],\n",
       "   [(2, 6), (7, 7)]],\n",
       "  [[(3, 3), (4, 7)], [(3, 4), (5, 7)], [(3, 5), (6, 7)], [(3, 6), (7, 7)]],\n",
       "  [[(4, 4), (5, 7)], [(4, 5), (6, 7)], [(4, 6), (7, 7)]],\n",
       "  [[(5, 5), (6, 7)], [(5, 6), (7, 7)]],\n",
       "  [[(6, 6), (7, 7)]],\n",
       "  ['(7, 7)']],\n",
       " [[[(0, 0), (1, 8)],\n",
       "   [(0, 1), (2, 8)],\n",
       "   [(0, 2), (3, 8)],\n",
       "   [(0, 3), (4, 8)],\n",
       "   [(0, 4), (5, 8)]],\n",
       "  [[(1, 1), (2, 8)],\n",
       "   [(1, 2), (3, 8)],\n",
       "   [(1, 3), (4, 8)],\n",
       "   [(1, 4), (5, 8)],\n",
       "   [(1, 5), (6, 8)]],\n",
       "  [[(2, 2), (3, 8)],\n",
       "   [(2, 3), (4, 8)],\n",
       "   [(2, 4), (5, 8)],\n",
       "   [(2, 5), (6, 8)],\n",
       "   [(2, 6), (7, 8)]],\n",
       "  [[(3, 3), (4, 8)],\n",
       "   [(3, 4), (5, 8)],\n",
       "   [(3, 5), (6, 8)],\n",
       "   [(3, 6), (7, 8)],\n",
       "   [(3, 7), (8, 8)]],\n",
       "  [[(4, 4), (5, 8)], [(4, 5), (6, 8)], [(4, 6), (7, 8)], [(4, 7), (8, 8)]],\n",
       "  [[(5, 5), (6, 8)], [(5, 6), (7, 8)], [(5, 7), (8, 8)]],\n",
       "  [[(6, 6), (7, 8)], [(6, 7), (8, 8)]],\n",
       "  [[(7, 7), (8, 8)]],\n",
       "  ['(8, 8)']],\n",
       " [[[(0, 0), (1, 9)],\n",
       "   [(0, 1), (2, 9)],\n",
       "   [(0, 2), (3, 9)],\n",
       "   [(0, 3), (4, 9)],\n",
       "   [(0, 4), (5, 9)]],\n",
       "  [[(1, 1), (2, 9)],\n",
       "   [(1, 2), (3, 9)],\n",
       "   [(1, 3), (4, 9)],\n",
       "   [(1, 4), (5, 9)],\n",
       "   [(1, 5), (6, 9)]],\n",
       "  [[(2, 2), (3, 9)],\n",
       "   [(2, 3), (4, 9)],\n",
       "   [(2, 4), (5, 9)],\n",
       "   [(2, 5), (6, 9)],\n",
       "   [(2, 6), (7, 9)]],\n",
       "  [[(3, 3), (4, 9)],\n",
       "   [(3, 4), (5, 9)],\n",
       "   [(3, 5), (6, 9)],\n",
       "   [(3, 6), (7, 9)],\n",
       "   [(3, 7), (8, 9)]],\n",
       "  [[(4, 4), (5, 9)],\n",
       "   [(4, 5), (6, 9)],\n",
       "   [(4, 6), (7, 9)],\n",
       "   [(4, 7), (8, 9)],\n",
       "   [(4, 8), (9, 9)]],\n",
       "  [[(5, 5), (6, 9)], [(5, 6), (7, 9)], [(5, 7), (8, 9)], [(5, 8), (9, 9)]],\n",
       "  [[(6, 6), (7, 9)], [(6, 7), (8, 9)], [(6, 8), (9, 9)]],\n",
       "  [[(7, 7), (8, 9)], [(7, 8), (9, 9)]],\n",
       "  [[(8, 8), (9, 9)]],\n",
       "  ['(9, 9)']]]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313c2622-f4d2-4562-98bf-64d97954ed54",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "18d1b00a-5887-407b-8814-f81b9e739474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import heapq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b7afcd-a41e-4f41-88ac-13d967e6bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_CYK_Model(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.device = 'cpu'\n",
    "        self.NT = args['NT']\n",
    "        self.T = args['T']\n",
    "        self.V = args['cnt_words']\n",
    "        self.s_dim = args['s_dim']\n",
    "        self.r = args['r_dim']\n",
    "        self.word_emb_size = args['word_emb_size']\n",
    "        self.enable_slide_windows = False if 'enable_slide_windows' not in args else args['enable_slide_windows']\n",
    "        self.window_size = False if 'window_size' not in args else args['window_size']\n",
    "        self.word_embedding = args['word_embedding']\n",
    "        self.grammar_unaries = args['grammar_unaries']\n",
    "        self.grammar_preterminates = args['grammar_preterminates']\n",
    "        self.grammar_double_nonterminates = args['grammar_double_nonterminates']\n",
    "        self.grammar_starts = args['grammar_starts']\n",
    "\n",
    "        self.merge_model = None\n",
    "        self.terminate_feature_generation_model = None\n",
    "        self.preterminate_feature_generation_model = None\n",
    "        \n",
    "        # check parameters\n",
    "        if (self.enable_slide_windows and self.window_size <= 0) or word == None\n",
    "            return None\n",
    "        reset_global_context()\n",
    "        \n",
    "    def reset_global_context(self):\n",
    "        self.records = []\n",
    "        self.windows_beginning_offset = 0\n",
    "\n",
    "    # each cell with form (possibility, feature_in_tensor, root_symbol_index)\n",
    "    def forward(self, word): # input a word at time t.\n",
    "        # generate the analysis of span [t, t]\n",
    "        w = self.get_terminate_parses(word)\n",
    "\n",
    "        # create cells for current time t.\n",
    "        current_record = [[]] if len(records) == 0 else [[]] * (len(records[-1]) + 1)\n",
    "\n",
    "        # fill the analysis of span [t, t] to the last cell of current time t.\n",
    "        current_record[-1] = w\n",
    "\n",
    "        # Sliding window control the maximum size of a record at time t.\n",
    "        # When the windows size is large, we may utilize array to store records, rather than list. The array allow us adopting \n",
    "        # sliding windows more effectively when the window size is large. However, we currently utilize list to store records.\n",
    "        # To do sliding window, we need first pop the first record (oldest record inside the window), and for each of rest records,\n",
    "        # we need pop its first element, as the first element of each record relate to the \"word\" we'd like to forget.\n",
    "        if enable_slide_windows:\n",
    "            while len(self.records) >= self.window_size:\n",
    "                self.records.pop(0)\n",
    "                for i in range(0, len(self.records)):\n",
    "                    self.records[i].pop(0)\n",
    "                windows_beginning_offset += 1\n",
    "\n",
    "        # Add record at current time to the global record set.\n",
    "        records.append(current_record)\n",
    "    \n",
    "        for inner_record_index in range(0, len(current_record) - 1):\n",
    "            current_record_length = len(current_record) \n",
    "            current_record[current_record_length - inner_record_index - 2] = []\n",
    "            cell_data = []\n",
    "            for split_index in range(current_record_length - inner_record_index - 2, t - windows_beginning_offset):\n",
    "                # coordination = (index, t)\n",
    "                cell1_coordination = (current_record_length - inner_record_index - 2, split_index)\n",
    "                cell2_coordination = (split_index + 1, t - windows_beginning_offset)\n",
    "                cell_data += self.merge_parses_in_two_cells(records[cell1_coordination[1]][cell1_coordination[0]],\\\n",
    "                                                           records[cell2_coordination[1]][cell2_coordination[0]],\\\n",
    "                                                           cell1_coordination, cell2_coordination)\n",
    "                current_record[current_record_length - inner_record_index - 2] = beam_search_strategy(cell_data) if beam_search_strategy is not None else cell_data\n",
    "        return heapq.nlargest(1, records[-1][0])[0][1]\n",
    "        \n",
    "        def get_unary_grammar_id(self, w):\n",
    "            return self.word_unary_grammar_id_mapping[w]\n",
    "\n",
    "        def get_grammar_for_generation(self, parse_i, parse_j):\n",
    "            return self.double_nonterminates_grammar_id_mapping[\"%s#%s\" % (str(parse_i[0]), str(parse_j[0]))]\n",
    "        \n",
    "        def get_terminate_parses(self, w):\n",
    "            unary_grammar_id = self.get_unary_grammar_id(w)\n",
    "            preterminate_grammar_id = self.preterminate_grammar_id(unary_grammar_id)\n",
    "            feature1 = self.terminate_feature_generation_model(self.word_embedding[w], self.grammar_unaries[unary_grammar_id])\n",
    "            feature2 = self.preterminate_feature_generation_model(feature1, self.grammar_preterminates[preterminate_grammar_id])\n",
    "            return [[1.0, feature1, unary_grammar_id], [1.0, feature2, preterminate_grammar_id]]\n",
    "        \n",
    "        def merge_parses_in_two_cells(self, cell1, cell2, cell1_id = None, cell2_id = None):\n",
    "            result = []\n",
    "            for parse_i in range(cell1):\n",
    "                for parse_j in range(cell2):\n",
    "                    p_1 = parse_i[0]\n",
    "                    p_2 = parse_j[1]\n",
    "                    g = self.get_grammar(parse_i, parse_j) # [begin_id, left_symbol_id, right_symbol_id, possibility]\n",
    "                    p = p_1 * p_2 * g[-1]\n",
    "                    feature = self.merge_model(parse_i[1], parse_j[2], g)\n",
    "                    result.append([p, feature, g[0]])\n",
    "            return result\n",
    "        \n",
    "        def select_tops(self, cell, beam_size = 5):\n",
    "            return heapq.nlargest(beam_size, cell)\n",
    "        \n",
    "        records = CKY_Algorithm(range(0, 10), get_terminate_parses, select_tops, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7d30b2c0-5560-444a-94db-6e83021925a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[132], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTNPCFG\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, args):\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m(TNPCFG, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class TNPCFG(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(TNPCFG, self).__init__()\n",
    "        print(\"build td pcfg\")\n",
    "        self.pcfg = TDPCFG()\n",
    "        self.device = 'cpu'\n",
    "        self.args = args\n",
    "        self.NT = args['NT']\n",
    "        self.T = args['T']\n",
    "        self.V = args['cnt_words']\n",
    "        self.s_dim = args['s_dim']\n",
    "        self.r = args['r_dim']\n",
    "        self.word_emb_size = args['word_emb_size']\n",
    "        if 'summary_parameters' in args and args['summary_parameters']:\n",
    "            print(\"device = %s, NT = %d, T = %d, V = %d, s_dim = %d, r = %d, word_emb_size = %d\" % \\\n",
    "                (self.device, self.NT, self.T, self.V, self.s_dim, self.r, self.word_emb_size))\n",
    "\n",
    "        ## root\n",
    "        self.root_emb = nn.Parameter(torch.randn(1, self.s_dim))\n",
    "        self.root_mlp = nn.Sequential(nn.Linear(self.s_dim, self.s_dim),\n",
    "                                      ResLayer(self.s_dim, self.s_dim),\n",
    "                                      ResLayer(self.s_dim, self.s_dim),\n",
    "                                      nn.Linear(self.s_dim, self.NT))\n",
    "\n",
    "        #terms\n",
    "        self.term_emb = nn.Parameter(torch.randn(self.T, self.s_dim))\n",
    "        self.term_mlp = nn.Sequential(nn.Linear(self.s_dim, self.s_dim),\n",
    "                                      ResLayer(self.s_dim, self.s_dim),\n",
    "                                      ResLayer(self.s_dim, self.s_dim),\n",
    "                                      nn.Linear(self.s_dim, self.V))\n",
    "\n",
    "        self.rule_state_emb = nn.Parameter(torch.randn(self.NT+self.T, self.s_dim))\n",
    "        rule_dim = self.s_dim\n",
    "        self.parent_mlp = nn.Sequential(nn.Linear(rule_dim,rule_dim),nn.ReLU(),nn.Linear(rule_dim,self.r))\n",
    "        self.left_mlp = nn.Sequential(nn.Linear(rule_dim,rule_dim), nn.ReLU(),nn.Linear(rule_dim,self.r))\n",
    "        self.right_mlp = nn.Sequential(nn.Linear(rule_dim,rule_dim),nn.ReLU(),nn.Linear(rule_dim,self.r))\n",
    "\n",
    "\n",
    "    def forward(self, input, **kwargs):\n",
    "        print(\"begin forward>>>>>>>>>>>>>\")\n",
    "        x = input['word']\n",
    "        print(\"x = %s\" % str(x))\n",
    "\n",
    "        b, n = x.shape[:2]\n",
    "        print(\"b, n = %d, %d\" % (b, n)) # batch and number?\n",
    "\n",
    "        def roots():\n",
    "            roots = self.root_mlp(self.root_emb).log_softmax(-1)\n",
    "            return roots.expand(b, roots.shape[-1]).contiguous()\n",
    "\n",
    "        def terms():\n",
    "            term_prob = self.term_mlp(self.term_emb).log_softmax(-1)\n",
    "            return term_prob[torch.arange(self.T)[None,None], x[:, :, None]]\n",
    "\n",
    "        def rules():\n",
    "            rule_state_emb = self.rule_state_emb\n",
    "            nonterm_emb = rule_state_emb[:self.NT]\n",
    "            head = self.parent_mlp(nonterm_emb).log_softmax(-1)\n",
    "            left = self.left_mlp(rule_state_emb).log_softmax(-2)\n",
    "            right = self.right_mlp(rule_state_emb).log_softmax(-2)\n",
    "            head = head.unsqueeze(0).expand(b,*head.shape)\n",
    "            left = left.unsqueeze(0).expand(b,*left.shape)\n",
    "            right = right.unsqueeze(0).expand(b,*right.shape)\n",
    "            return (head, left, right)\n",
    "\n",
    "        root, unary, (head, left, right) = roots(), terms(), rules()\n",
    "        print(unary.shape, root.shape, head.shape, left.shape, right.shape)\n",
    "        return {'unary': unary,\n",
    "                'root': root,\n",
    "                'head': head,\n",
    "                'left': left,\n",
    "                'right': right,\n",
    "                'kl': 0}\n",
    "\n",
    "    def loss(self, input):\n",
    "        rules = self.forward(input)\n",
    "        result = self.pcfg._inside(rules=rules, lens=input['seq_len'])\n",
    "        logZ = -result['partition'].mean()\n",
    "        return logZ\n",
    "\n",
    "    def evaluate(self, input, decode_type, **kwargs):\n",
    "        rules = self.forward(input)\n",
    "        if decode_type == 'viterbi':\n",
    "            assert NotImplementedError\n",
    "        elif decode_type == 'mbr':\n",
    "            return self.pcfg.decode(rules=rules, lens=input['seq_len'], viterbi=False, mbr=True)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    def get_top_k(data, k = 1):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "aefcc85f-7746-43ac-839a-20c78b99a572",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'max'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[139], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.999\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m23124\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m9.45\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2124\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m33\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'max'"
     ]
    }
   ],
   "source": [
    "[(0.999, [23124]), (9.45, [2124,33])].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "155102a3-04f1-452f-a21b-2b7008d8c8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, [1, 2, 3]]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heapq.nlargest(1, [[1, [1,2,3]]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218e3624-6aa7-4ac1-88a0-7845029edfd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
